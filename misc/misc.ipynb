{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img, ax=None, vmin=None, vmax=None, figsize=(7, 7), external=False, title=\"\"):\n",
    "    if external:\n",
    "        cv.imshow(\"imshow\", img)\n",
    "        \n",
    "        while 1:\n",
    "            if cv.waitKey(0) & 0xFF == ord(\"q\"):\n",
    "                break\n",
    "        \n",
    "        cv.destroyAllWindows()\n",
    "        return\n",
    "    \n",
    "    gray = False\n",
    "\n",
    "    if len(img.shape) == 2:\n",
    "        gray = True\n",
    "    if img.shape == 3 and img.shape[-1] == 1:\n",
    "        gray = True\n",
    "\n",
    "    # trying to remove as much as possible\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots(figsize=figsize)\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax.set_title(title)\n",
    "    ax.autoscale(tight=True)\n",
    "    \n",
    "    if gray:\n",
    "        ax.imshow(img, cmap=\"gray\", vmin=vmin, vmax=vmax)\n",
    "    else:\n",
    "        ax.imshow(img[:, :, ::-1], vmin=vmin, vmax=vmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color Correction\n",
    "\n",
    "### Contrast Limited Adaptive Histogram Equalization (CLAHE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clahe(img, grid_size=7):\n",
    "    clh_obj = cv.createCLAHE(clipLimit=2.0, tileGridSize=(grid_size, grid_size))\n",
    "    lab_space = cv.cvtColor(img, cv.COLOR_BGR2LAB)\n",
    "    img_channels = cv.split(lab_space)\n",
    "    img_channels[0] = clh_obj.apply(img_channels[0])\n",
    "    return cv.cvtColor(cv.merge(img_channels), cv.COLOR_LAB2BGR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"images/fullbody.jpg\")\n",
    "clahe_img = clahe(img)\n",
    "imshow(np.hstack([img, clahe_img]), figsize=(15, 15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face and Body Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_box(img, bounding_box):\n",
    "    img = img.copy()\n",
    "    x, y, w, h = bounding_box\n",
    "    \n",
    "    return cv.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://github.com/opencv/opencv/raw/master/data/haarcascades/haarcascade_frontalface_default.xml -O haarcascade_frontalface_default.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_face(img):\n",
    "    img = img.copy()\n",
    "    img_gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    face_cascade = cv.CascadeClassifier()\n",
    "\n",
    "    if not face_cascade.load(cv.samples.findFile(\"./haarcascade_frontalface_default.xml\")):\n",
    "        print(\"--(!)Error loading face cascade\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    try:\n",
    "        face = face_cascade.detectMultiScale(img_gray)[0]\n",
    "    except IndexError as e:\n",
    "        print(e)\n",
    "        print(\"--(!)No faces detected\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    return face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_body(img, face_bounds):\n",
    "    # image height\n",
    "    hi = img.shape[0]\n",
    "\n",
    "    # face bounds\n",
    "    xf, yf, wf, hf = face_bounds\n",
    "    \n",
    "    # x_body_left = x_face_left - wf\n",
    "    x = xf - wf\n",
    "    # y_body_top = y_face_top - hf\n",
    "    y = yf - hf\n",
    "    w = 3 * wf\n",
    "    h = hi - y\n",
    "    \n",
    "    return (x, y, w, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_bounds = get_face(clahe_img)\n",
    "body_bounds = get_body(clahe_img, face_bounds)\n",
    "boxed_face = draw_box(clahe_img, face_bounds)\n",
    "boxed_body = draw_box(boxed_face, body_bounds)\n",
    "imshow(boxed_body)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
