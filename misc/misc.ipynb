{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img, ax=None, vmin=None, vmax=None, figsize=(7, 7), external=False, title=\"\"):\n",
    "    if external:\n",
    "        cv.imshow(\"imshow\", img)\n",
    "        \n",
    "        while 1:\n",
    "            if cv.waitKey(0) & 0xFF == ord(\"q\"):\n",
    "                break\n",
    "        \n",
    "        cv.destroyAllWindows()\n",
    "        return\n",
    "    \n",
    "    gray = False\n",
    "\n",
    "    if len(img.shape) == 2:\n",
    "        gray = True\n",
    "    if img.shape == 3 and img.shape[-1] == 1:\n",
    "        gray = True\n",
    "\n",
    "    # trying to remove as much as possible\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots(figsize=figsize)\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax.set_title(title)\n",
    "    ax.autoscale(tight=True)\n",
    "    \n",
    "    if gray:\n",
    "        ax.imshow(img, cmap=\"gray\", vmin=vmin, vmax=vmax)\n",
    "    else:\n",
    "        ax.imshow(img[:, :, ::-1], vmin=vmin, vmax=vmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color Conversion from RGB to CIE L\\*a\\*b\\*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(X):\n",
    "    \n",
    "    X = X.copy()\n",
    "    \n",
    "    mask1 = (X >  0.008856)\n",
    "    mask2 = (X <= 0.008856)\n",
    "    \n",
    "    X[mask1] = X[mask1]**(1/3)\n",
    "    X[mask2] = (7.787*X[mask2]) + (16/116)\n",
    "    \n",
    "    return X\n",
    "\n",
    "def rgb2lab(img):\n",
    "    \n",
    "    img = img.astype('float64')\n",
    "    img /= 255.\n",
    "    \n",
    "    img = img**2.2\n",
    "    \n",
    "    \n",
    "    X = (img[:,:,0] * 0.412453) + (img[:,:,1] * 0.357580) + (img[:,:,2] * 0.180423)\n",
    "    Y = (img[:,:,0] * 0.212671) + (img[:,:,1] * 0.715160) + (img[:,:,2] * 0.072169)\n",
    "    Z = (img[:,:,0] * 0.019334) + (img[:,:,1] * 0.119193) + (img[:,:,2] * 0.950227)\n",
    "    \n",
    "    Xn = 0.950456\n",
    "    Zn = 1.088754\n",
    "    delta = 0\n",
    "\n",
    "    X /= Xn\n",
    "    Z /= Zn\n",
    "    \n",
    "    mask1 = (Y >  0.008856)\n",
    "    mask2 = (Y <= 0.008856)\n",
    "    \n",
    "    L = Y.copy()\n",
    "    L[mask1] = (116*(L[mask1]**(1/3)) - 16)\n",
    "    L[mask2] = 903.3*L[mask2]\n",
    "    \n",
    "    a = 500 * (f(X) - f(Y)) + delta\n",
    "    b = 200 * (f(Y) - f(Z)) + delta\n",
    "    \n",
    "    L = L*(255/100)\n",
    "    a = a + 128\n",
    "    b = b + 128\n",
    "    \n",
    "    return np.round(np.dstack([L,a,b])).astype('uint8')        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color Correction\n",
    "\n",
    "### Contrast Limited Adaptive Histogram Equalization (CLAHE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _interpolate(c_sub_bin, map_ul, map_ur, map_dl, map_dr, x_frame_size, y_frame_size):\n",
    "   \n",
    "    c_sub_image = np.zeros(c_sub_bin.shape)\n",
    "\n",
    "    for i in range(x_frame_size):\n",
    "        i_inv = x_frame_size-i\n",
    "        for j in range(y_frame_size):\n",
    "            j_inv = y_frame_size-j\n",
    "            \n",
    "            val = c_sub_bin[i,j].astype(int)\n",
    "            c_sub_image[i,j] = i_inv*(j_inv*map_ul[val] + \\\n",
    "                                          j*map_ur[val])+ \\\n",
    "                                i*(j_inv*map_dl[val] + \\\n",
    "                                   j*map_dr[val])\n",
    "\n",
    "    return (c_sub_image/(x_frame_size*y_frame_size)).astype('int32')\n",
    "\n",
    "def generate_histograms(bins, n_bins, grid_x_divs, grid_y_divs, x_frame_size, y_frame_size):\n",
    "    \n",
    "    hist = np.zeros((grid_x_divs,grid_y_divs,n_bins))\n",
    "    \n",
    "    for i in range(grid_x_divs):\n",
    "        for j in range(grid_y_divs):\n",
    "\n",
    "            # gets the current frame (it's binned values)\n",
    "            c_bin = bins[i*x_frame_size : (i+1)*x_frame_size, \n",
    "                         j*y_frame_size : (j+1)*y_frame_size]\n",
    "            c_bin = c_bin.astype('int32')\n",
    "            \n",
    "            # updates the current frame's histogram\n",
    "            for p in range(x_frame_size):\n",
    "                for q in range(y_frame_size):\n",
    "                    hist[i,j,c_bin[p,q]]+=1 \n",
    "    \n",
    "    return hist\n",
    "\n",
    "def clip_histogram(hist, clip_limit, n_bins, grid_x_divs, grid_y_divs):\n",
    "\n",
    "    for i in range(grid_x_divs):\n",
    "        for j in range(grid_y_divs):\n",
    "            \n",
    "            total_overflow = 0\n",
    "            for c_bin in range(n_bins):\n",
    "                overflow = hist[i,j,c_bin] - clip_limit\n",
    "                if overflow > 0:\n",
    "                    total_overflow += overflow\n",
    "            \n",
    "            # to redistribute intensities across each bin\n",
    "            inc_bin_val = total_overflow/n_bins\n",
    "            \n",
    "            # new upper limit for each bin based on how the redistribution has to be done\n",
    "            upper = clip_limit - inc_bin_val\n",
    "            \n",
    "            # redistributing\n",
    "            for c_bin in range(n_bins):\n",
    "                if hist[i,j,c_bin] > clip_limit:\n",
    "                    hist[i,j,c_bin] = clip_limit\n",
    "                else:\n",
    "                    if hist[i,j,c_bin] > upper:\n",
    "                        total_overflow -= (hist[i,j,c_bin] - upper)\n",
    "                        hist[i,j,c_bin] = clip_limit\n",
    "                    else:\n",
    "                        hist[i,j,c_bin] += inc_bin_val\n",
    "                        total_overflow -= inc_bin_val\n",
    "                       \n",
    "            # if there is still some overflow, then uniformly divide the overflow into each bin\n",
    "            if total_overflow > 0:\n",
    "                \n",
    "                div_uniform = max(1, 1+total_overflow//n_bins)\n",
    "                \n",
    "                for c_bin in range(n_bins):\n",
    "                    hist[i,j,c_bin] += div_uniform\n",
    "                    total_overflow -= div_uniform\n",
    "                    if total_overflow <= 0:\n",
    "                        break\n",
    "    return hist\n",
    "\n",
    "def create_eq_mappings(hist, n_bins, frame_size, grid_x_divs, grid_y_divs):\n",
    "    max_val = 255\n",
    "    min_val = 0\n",
    "    \n",
    "    maps = np.zeros((grid_x_divs,grid_y_divs,n_bins))\n",
    "    scale = (max_val - min_val)/float(frame_size)\n",
    "\n",
    "    for i in range(grid_x_divs):\n",
    "        for j in range(grid_y_divs):\n",
    "            \n",
    "            c_sum = 0\n",
    "            for c_bin in range(n_bins):\n",
    "                c_sum += hist[i,j,c_bin]\n",
    "                maps[i,j,c_bin] = np.clip((c_sum * scale) + min_val, \\\n",
    "                                          min_val, \\\n",
    "                                          max_val)\n",
    "    return maps\n",
    "\n",
    "def interpolate(res, maps, bins, grid_x_divs, grid_y_divs, x_frame_size, y_frame_size):\n",
    "    x_offset = 0\n",
    "    for i in range(grid_x_divs):\n",
    "\n",
    "        x_up = max(0,i-1)\n",
    "        x_down = min(i, grid_x_divs-1)\n",
    "        \n",
    "        y_offset = 0\n",
    "        for j in range(grid_y_divs):\n",
    "      \n",
    "            y_left = max(0,j-1)\n",
    "            y_right = min(j, grid_y_divs-1)\n",
    "                \n",
    "            map_ul = maps[x_up, y_left]\n",
    "            map_ur = maps[x_up, y_right]\n",
    "            map_dl = maps[x_down, y_left]\n",
    "            map_dr = maps[x_down, y_right]\n",
    "            \n",
    "            c_sub_bin = bins[x_offset : x_offset + x_frame_size, \\\n",
    "                             y_offset : y_offset + y_frame_size\n",
    "                            ]\n",
    "\n",
    "            c_sub_image = _interpolate(c_sub_bin, map_ul, map_ur, map_dl, map_dr, \\\n",
    "                                      x_frame_size, y_frame_size\n",
    "                                     )\n",
    "            \n",
    "            res[x_offset : x_offset+x_frame_size, y_offset : y_offset+y_frame_size] = c_sub_image\n",
    "            y_offset += y_frame_size\n",
    "        x_offset += x_frame_size\n",
    "    \n",
    "    return res\n",
    "    \n",
    "\n",
    "def clahe(img, clip_limit=3.0, n_bins=256, grid=(7,7)):\n",
    "\n",
    "    h,w = img.shape\n",
    "    grid_x_divs, grid_y_divs = list(map(lambda x: int(x), grid))\n",
    "    \n",
    "    # find amount of padding needed and apply\n",
    "    padding_x = grid_x_divs - int(h % grid_x_divs)\n",
    "    padding_y = grid_y_divs - int(w % grid_y_divs)\n",
    "    \n",
    "    if padding_x!=0:\n",
    "        img = np.append(img,np.zeros((padding_x,img.shape[1])).astype(int),axis=0)\n",
    "    if padding_y!=0:\n",
    "        img = np.append(img,np.zeros((img.shape[0],padding_y)).astype(int),axis=1)\n",
    "    \n",
    "    # initialize result\n",
    "    res = np.zeros(img.shape)\n",
    "\n",
    "    # get size of each cell/frame in the grid\n",
    "    x_frame_size = int(img.shape[0]/grid_x_divs)\n",
    "    y_frame_size = int(img.shape[1]/grid_y_divs)\n",
    "    frame_size = x_frame_size*y_frame_size\n",
    "    \n",
    "    # set clip limit\n",
    "    clip_limit = max(5,clip_limit*x_frame_size*y_frame_size/n_bins)\n",
    "    \n",
    "    # generate Look Up Table and put pixel intensities into their bins\n",
    "    bin_size = 256./n_bins\n",
    "    LUT = (np.arange(256)/bin_size).astype('int32')\n",
    "    bins = LUT[img]\n",
    "    \n",
    "    # creating separate histograms for each frame/cell\n",
    "    hist = generate_histograms(bins, n_bins, grid_x_divs, grid_y_divs, x_frame_size, y_frame_size)\n",
    "    \n",
    "    # clipping the histogram to limit contrast\n",
    "    hist = clip_histogram(hist, clip_limit, n_bins, grid_x_divs, grid_y_divs)\n",
    "    \n",
    "    # creating the equalization mapping\n",
    "    maps = create_eq_mappings(hist, n_bins, frame_size, grid_x_divs, grid_y_divs)\n",
    "    \n",
    "    # Interpolating the values from surrounding frames\n",
    "    res = interpolate(res, maps, bins, grid_x_divs, grid_y_divs, x_frame_size, y_frame_size)\n",
    "    \n",
    "    # return result without padding\n",
    "    return res[:h, :w].astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_clahe(img, clip_limit=3.0, n_bins=256, grid=(7,7)):\n",
    "\n",
    "    img = img[:,:,::-1]\n",
    "    img_lab = rgb2lab(img)\n",
    "    \n",
    "    clahe_L = clahe(img_lab[:,:,0], clip_limit, n_bins, grid)\n",
    "\n",
    "    img_clahe = np.dstack([clahe_L, img_lab[:,:,1], img_lab[:,:,2]])\n",
    "    return cv.cvtColor(img_clahe, cv.COLOR_LAB2BGR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLAHE Implemention\n",
    "\n",
    "The above writen `apply_clahe()` function takes in 4 inputs:\n",
    "* The input image in **BGR** format\n",
    "* The clip limit for contrast limiting\n",
    "* Number of bins to divide the image into\n",
    "* Grid size to be used while performing adaptive histogram equalization\n",
    "\n",
    "The `clahe()` function performs the following 4 step process to perform color correction:\n",
    "* Divides the image into frames/cells using the grid values passed to the function\n",
    "* Creates a separate histogram for each cell/frame after binning the values based on the value passed to the function\n",
    "* The histogram equalization mapping for each cell/frame is also generated\n",
    "* Next, the contrast of the image is limited by clipping bin values if they are above a 'clip limit' \n",
    "* Finally, adaptive histogram equalization is performed by interpolating the value for each frame by using neighboring frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img = cv.imread(\"images/fullbody.jpg\")\n",
    "\n",
    "clahe_img = apply_clahe(img)\n",
    "_, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 15))\n",
    "imshow(img, ax=ax1)\n",
    "imshow(clahe_img, ax=ax2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face and Body Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_box(img, bounding_box):\n",
    "    img = img.copy()\n",
    "    x, y, w, h = bounding_box\n",
    "    \n",
    "    return cv.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://github.com/opencv/opencv/raw/master/data/haarcascades/haarcascade_frontalface_default.xml -O haarcascade_frontalface_default.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_face(img):\n",
    "    img = img.copy()\n",
    "    img_gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    face_cascade = cv.CascadeClassifier()\n",
    "\n",
    "    if not face_cascade.load(cv.samples.findFile(\"./haarcascade_frontalface_default.xml\")):\n",
    "        print(\"--(!)Error loading face cascade\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    try:\n",
    "        face = face_cascade.detectMultiScale(img_gray)[0]\n",
    "    except IndexError as e:\n",
    "        print(e)\n",
    "        print(\"--(!)No faces detected\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    return face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_body(img, face_bounds):\n",
    "    # image height\n",
    "    hi = img.shape[0]\n",
    "\n",
    "    # face bounds\n",
    "    xf, yf, wf, hf = face_bounds\n",
    "    \n",
    "    # x_body_left = x_face_left - wf\n",
    "    x = xf - wf\n",
    "    # y_body_top = y_face_top - hf\n",
    "    y = yf - hf\n",
    "    w = 3 * wf\n",
    "    h = hi - y\n",
    "    \n",
    "    return (x, y, w, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_bounds = get_face(clahe_img)\n",
    "body_bounds = get_body(clahe_img, face_bounds)\n",
    "boxed_face = draw_box(clahe_img, face_bounds)\n",
    "boxed_body = draw_box(boxed_face, body_bounds)\n",
    "imshow(boxed_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.imwrite(\"images/outputs/fb-detect.png\", boxed_body)\n",
    "cv.imwrite(\"images/outputs/col-corr.png\", clahe_img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
